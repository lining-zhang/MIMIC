# model
model_path: /Users/lining_zhang/Desktop/research/vocab_model
vocab_obj_path:

# data
train_path: /Users/lining_zhang/Desktop/research/MIMIC/data/train_notes.txt
valid_path: /Users/lining_zhang/Desktop/research/MIMIC/data/valid_notes.txt
test_path: /Users/lining_zhang/Desktop/research/MIMIC/data/test_notes.txt

batch_size:
num_epoch: 100
mask_prob: 0.15
learning_rate: 0.001
betas:
is_train:

attn_path:












# project:
project: EGFR
code_path: /mfs/home/liucancheng/NetFrame
model_dir: ../snapshots

# data:
train_path: /mfs/meta/EGFR/patch_list/v0_scale20_320_320_without_wealy_train.txt
valid_path: /mfs/meta/EGFR/patch_list/v0_scale20_320_320_without_wealy_test.txt
test_path: /mfs/meta/EGFR/patch_list/v0_scale20_320_320_without_wealy_test.txt
small_path: /mfs/meta/EGFR/patch_list/v0_scale20_320_320_without_wealy_test.txt

# data argumentation
random_mirror: True
color_jitter: True
random_blur: True
random_scale: True

# hps:
num_classes: 2
learning_rate: !!float 1e-4
lr_decay_step: 20000
lr_decay_ratio: 0.5
batch_size: 12

resnet_layer: 50
input_size: 320
patch_size: 320

# train:
gpu: [0]
restore_iters: 0
log_label: 1
save_step: 1000
max_steps: 120005
monitor_class: 1
l2_loss_lambda: !!float 1e-5

class_weight: [1.0, 1.0]

experiments:
    0:
        gpu: [0, 1, 2, 3, 4, 5, 6, 7, 8]
        batch_size: 24
        # test_path: /mfs/meta/EGFR/patch_list/v0_scale20_320_320_without_wealy_test_small.txt


# nohup /usr/bin/python -u main.py --config_file ./config/EGFR/config_EGFR_v0.yaml --version v0_0  >> logs/EGFR/EGFR_v0_0.log &
# nohup /usr/bin/python -u main.py --config_file ./config/EGFR/config_EGFR_v0.yaml --version v0_0 --mode test --restore_iters 12000 >> logs/EGFR/EGFR_v0_0_test.log &